{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a6c948d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91d5f46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bf3a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "867f3343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7e99cf",
   "metadata": {},
   "source": [
    "## Summary\n",
    "The k-Nearest Neighbors (KNN) algorithm is a simple and intuitive classification and regression method in machine learning. It operates on the principle that instances with similar features tend to belong to the same class. KNN is a non-parametric algorithm, meaning it doesn't make any assumptions about the underlying data distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5094a133",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Given a dataset $\\{\\mathbf{X}, \\mathbf{Y}\\}$:\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \\begin{bmatrix}\n",
    "x_{11} & \\dots & x_{1d}\\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "x_{n1} & \\dots & x_{nd}\n",
    "\\end{bmatrix}\n",
    "\\quad \\text{and} \\quad\n",
    "\\mathbf{Y} = \\begin{bmatrix}\n",
    "y_1\\\\\n",
    "\\vdots\\\\\n",
    "y_n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where the independent variables (also called inputs, predictors, or covariates) are represented by the matrix $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ and the dependent variable (also known as output, target, label, or response variable) is represented by the vector $\\mathbf{Y} \\in \\mathbb{R}^{n \\times 1}$, with $n$ being the number of training examples and $d$ being the number of features. \n",
    "\n",
    "The goal is to utilize a supervised learning approach, either for regression or classification tasks, by identifying the $k$ training examples that are closest to a new instance (test point) using a specified distance metric (such as the Euclidean distance). The class (or value) of the new instance is determined through a majority vote (in classification) or by averaging (in regression) the classes (or values) of its $k$ nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5260a3",
   "metadata": {},
   "source": [
    "## Distance Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53676032",
   "metadata": {},
   "source": [
    "The most common distance metric used in KNN is the Euclidean distance between two points $\\mathbf{p}$ and $\\mathbf{q}$ in a $d$-dimensional space:\n",
    "\n",
    "$$\n",
    "\\text{EuclideanDistance}(\\mathbf{p}, \\mathbf{q}) = \\sqrt{\\sum_{i=1}^{d} (p_i - q_i)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8318ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(p, q):\n",
    "#   return np.linalg.norm(p - q)\n",
    "    return np.sqrt(np.sum((p - q)**2)) #alternatively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71d86851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.array([1,1])\n",
    "q = np.array([10,1])\n",
    "euclidean_distance(p, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563bdd5f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4528f8a",
   "metadata": {},
   "source": [
    "Let $k$ be the number of neighbors to consider. The predicted class $y_{\\text{pred}}$ of the new instance $x$ using KNN can be defined as:\n",
    "\n",
    "$$\n",
    "y_{\\text{pred}}(x) = \\arg\\max_{c} \\sum_{i=1}^{k} \\delta(y_i, c)\n",
    "$$\n",
    "\n",
    "where $y_i$ is the class label of the $i$th nearest neighbor of $x$, $c$ is a class label, and $\\delta(y_i, c)$ is the Kronecker delta function that equals 1 if $y_i = c$ and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea0f673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_train, y, x_input, k):\n",
    "    op_labels = []\n",
    "    for item in x_input:\n",
    "        point_dist = []\n",
    "        for j in range(len(x_train)):\n",
    "            distances = euclidean_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5727e0f",
   "metadata": {},
   "source": [
    "3. **Regression using KNN:**\n",
    "In the case of regression, KNN can be used to predict a continuous target value. Given a new instance $x$, the predicted target value $y_{\\text{pred}}$ can be calculated as the average of the target values of its k nearest neighbors:\n",
    "\n",
    "$$\n",
    "y_{\\text{pred}}(x) = \\frac{1}{k} \\sum_{i=1}^{k} y_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27baf774",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7023d697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width         species\n",
       "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
       "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
       "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
       "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
       "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = sample_data.iris_data()\n",
    "X = iris[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abd38b2",
   "metadata": {},
   "source": [
    "## Model\n",
    "For finding the distance between points, we can use the Euclidean distance metric which is $$\n",
    "d(x, x') = \\sqrt{(x_i - x_i')^2 + \\dots + (x_n - x_n')^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b23bab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b25b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNeighborsClassifier():\n",
    "    def __init__(self, k=3, dist_metric=euclidean_distance):\n",
    "        self.k = k\n",
    "        self.dist_metric = dist_metric    \n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train    \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        neighbors = []\n",
    "        for x in X_test:\n",
    "            distances = self.dist_metric(x, self.X_train)\n",
    "            y_sorted = [y for _, y in sorted(zip(distances, self.y_train))]\n",
    "            neighbors.append(y_sorted[:self.k])        \n",
    "            return list(map(most_common, neighbors))    \n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        accuracy = sum(y_pred == y_test) / len(y_test)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8e3a54f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m ks:\n\u001b[1;32m      4\u001b[0m     knn \u001b[38;5;241m=\u001b[39m KNeighborsClassifier(k\u001b[38;5;241m=\u001b[39mk)\n\u001b[0;32m----> 5\u001b[0m     knn\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m      6\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n\u001b[1;32m      7\u001b[0m     accuracies\u001b[38;5;241m.\u001b[39mappend(accuracy)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "ks = range(1, 30)\n",
    "for k in ks:\n",
    "    knn = KNeighborsClassifier(k=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    accuracy = knn.evaluate(X_test, y_test)\n",
    "    accuracies.append(accuracy)\n",
    "    fig, ax = plt.subplots()\n",
    "ax.plot(ks, accuracies)\n",
    "ax.set(xlabel=\"k\",\n",
    "       ylabel=\"Accuracy\",\n",
    "       title=\"Performance of knn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c93b4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
